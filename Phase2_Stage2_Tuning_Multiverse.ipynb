{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"L4","mount_file_id":"1y6EFRIr3UsuJ41KWOvhKZrSGqsC-9DVa","authorship_tag":"ABX9TyPapmAYXIW99Tz5lCVw1Juy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import torch\n","print(\"CUDA available:\", torch.cuda.is_available())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hV9SFr5KD7Ym","executionInfo":{"status":"ok","timestamp":1745167391297,"user_tz":240,"elapsed":1682,"user":{"displayName":"Praveen Vemasani","userId":"00723242222486514580"}},"outputId":"74d71f35-e800-480b-9f89-e436f39f792b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["CUDA available: True\n"]}]},{"cell_type":"code","source":["import shutil\n","import os\n","\n","# Remove the mount folder if it already exists\n","if os.path.exists('/content/drive'):\n","    shutil.rmtree('/content/drive')\n"],"metadata":{"id":"GpyjAn1j9WI1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FPChpAgu9XBd","executionInfo":{"status":"ok","timestamp":1745182335698,"user_tz":240,"elapsed":14451,"user":{"displayName":"Praveen Vemasani","userId":"00723242222486514580"}},"outputId":"9276f5bb-838c-4a25-ce33-93bec54933a6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import os\n","import shutil\n","\n","# Path to your main dataset directory\n","base_path = \"/content/drive/MyDrive/Colab Notebooks/NLP_DreamBooth\"\n","\n","# Folders to merge\n","folders = [\n","    \"Wizard_Images\",\n","    \"Dragon_Images\",\n","    \"Princess_Images\",\n","    \"Nature_Images\",\n","    \"Scene_Transitions\"\n","]\n","\n","# Destination folder\n","merged_folder = os.path.join(base_path, \"all_training_images\")\n","os.makedirs(merged_folder, exist_ok=True)\n","\n","# Supported image formats\n","image_exts = [\".jpg\", \".jpeg\", \".png\", \".webp\"]\n","\n","# Merge and rename logic\n","for folder in folders:\n","    folder_path = os.path.join(base_path, folder)\n","    count = 1\n","    for fname in sorted(os.listdir(folder_path)):\n","        ext = os.path.splitext(fname)[1].lower()\n","        if ext in image_exts:\n","            new_filename = f\"{folder}_img_{count}{ext}\"\n","            src = os.path.join(folder_path, fname)\n","            dst = os.path.join(merged_folder, new_filename)\n","            shutil.copy2(src, dst)\n","            count += 1\n","\n","print(f\"✅ All images successfully merged into:\\n{merged_folder}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qkQ1tCdq-Oj-","executionInfo":{"status":"ok","timestamp":1745182366567,"user_tz":240,"elapsed":20531,"user":{"displayName":"Praveen Vemasani","userId":"00723242222486514580"}},"outputId":"d6899b8f-3e02-4d0d-b533-9a341e6784bb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ All images successfully merged into:\n","/content/drive/MyDrive/Colab Notebooks/NLP_DreamBooth/all_training_images\n"]}]},{"cell_type":"code","source":["import os\n","\n","captions = {\n","    \"Dragon_Images_img_1.png\": \"A cheerful green dragon with red-orange wings happily playing near a spring stream, splashing water with its foot in a sunny meadow. The background features blooming yellow flowers, rocks, grassy hills, and trees, with a soft watercolor sky and light clouds. The illustration is done in a classic children's storybook style with warm tones, hand-drawn comic lines, and whimsical energy.\",\n","    \"Dragon_Images_img_2.png\": \"A young wizard with curly red-brown hair wearing a blue robe and pointed hat, casting a playful glowing spell with his wand toward a friendly green dragon. The dragon smiles warmly, sitting calmly in a forest clearing surrounded by trees and plants. The illustration is in a classic children’s storybook style, with watercolor textures, soft linework, and warm earthy tones, creating a magical and whimsical scene.\",\n","    \"Dragon_Images_img_3.png\": \"A cheerful green dragon with red-orange wings flying joyfully through the sky over grassy hills and scattered trees. The background features rolling green hills, fluffy white clouds, and a soft blue sky. Illustrated in a classic children’s storybook style with hand-drawn comic lines and watercolor texture, using warm, earthy tones and a whimsical mood.\",\n","    \"Dragon_Images_img_4.png\": \"A fierce green dragon with red wings breathing a large burst of orange and yellow fire from its mouth. The dragon stands with an angry expression in front of a cave entrance, surrounded by rocks, trees, and grass. The illustration is in a classic children’s storybook style with watercolor texture, hand-drawn comic lines, and warm earthy tones.\",\n","    \"Dragon_Images_img_5.png\": \"A cheerful princess in a pink dress is playing joyfully with a friendly green dragon in a sunny meadow filled with flowers and trees. Nearby, a young wizard in a blue robe and pointed hat watches protectively while holding a glowing staff. The scene is rendered in a classic children's storybook style with watercolor textures, soft comic-style linework, and a warm, magical atmosphere.\",\n","\n","    \"Nature_Images_img_1.png\": \"A vibrant, enchanting digital illustration of a magical portal hidden within a lush, fantastical forest. The oval-shaped portal is formed by swirling, moss-covered vines and ancient rock formations, revealing a breathtaking view of a sparkling waterfall cascading into a crystal-clear pool beyond. The surrounding forest teems with vibrant, otherworldly flora—delicate pink lotus-like flowers, clusters of blue and pink blossoms, and whimsical trees with bright green and rosy pink foliage. The sky seen through the portal is bright and serene, suggesting daylight, while the foreground remains softly shaded beneath the forest canopy. The overall style is whimsical, dreamlike, and rich in color, evoking a sense of wonder and discovery—as if inviting the viewer into a magical realm.\",\n","    \"Nature_Images_img_2.png\": \"A small, detailed, and award-worthy digital artwork depicting a magical portal hidden deep within a lush, fantastical forest. The oval-shaped portal is crafted from swirling, moss-covered vines and ancient, weathered stone, framing a stunning view of a tranquil waterfall cascading into a crystal-clear pool. The surrounding forest is teeming with vibrant, otherworldly flora—pink lotus-like blooms, clusters of blue and pink blossoms, and whimsically shaped trees with bright green and rosy pink foliage. Soft, ethereal light filters through the canopy, creating a dreamy contrast between the shaded foreground and the bright, serene sky seen through the portal. The overall style is whimsical and dreamlike, featuring a pastel color palette, intricate textures, and a high-quality, painterly aesthetic.\",\n","    \"Nature_Images_img_3.png\": \"A breathtaking, storybook-style digital painting depicting a hidden waterfall deep within a mystical rainforest. The waterfall cascades gently over moss-covered rocks into a crystal-clear pool, surrounded by lush greenery and vibrant, colorful flowers. Soft beams of sunlight filter through the dense forest canopy, casting a warm, magical glow over the scene. The artwork features rich textures and a vivid color palette, blending the depth and charm of a classic oil painting with a whimsical, dreamlike atmosphere.\",\n","    \"Nature_Images_img_4.png\": \"A breathtaking fantasy landscape bathed in soft, golden light, where cherry blossom trees and vibrant meadows line a crystal-clear stream winding through a magical valley—framed by distant misty mountains and towering evergreens, evoking a serene and dreamlike escape into another world.\",\n","    \"Nature_Images_img_5.png\": \"A magical meadow teeming with whimsical, storybook charm—colorful blossoms, oversized mushrooms, and glowing lotuses surround a sparkling stream that winds through lush, enchanted greenery beneath pastel skies, evoking the wonder of a fantastical natural world.\",\n","\n","    \"Princess_Images_img_1.png\": \"A young princess with golden-orange curly hair and fair skin, wearing a pink dress and a golden crown, standing in a neutral pose with a gentle smile. She is illustrated in a classic children's storybook style with hand-drawn lines and soft watercolor textures, set against a warm beige background with light pencil shading and subtle texture.\",\n","    \"Princess_Images_img_2.png\": \"A joyful young princess with golden-orange curly hair and a pink dress dancing gracefully in a sunny garden. She wears a golden crown and twirls with a smile, surrounded by green bushes and yellow flowers. The illustration is done in a classic children's storybook style with soft watercolor textures, warm tones, and hand-drawn comic-style linework.\",\n","    \"Princess_Images_img_3.png\": \"A young princess in a pink dress with a golden crown joyfully reaching out toward a young wizard in a blue robe and pointed hat. The wizard holds a glowing wand and smiles warmly at her. They are playing together in a sunny meadow filled with yellow flowers and surrounded by trees, with rolling hills and fluffy clouds in the background. The scene is illustrated in a classic children’s storybook style with watercolor textures and soft, hand-drawn lines.\",\n","    \"Princess_Images_img_4.png\": \"A young princess with soft golden-brown curls and a warm smile stands in a sunny meadow, wearing a flowing pink dress and a golden crown. She gestures joyfully as if welcoming someone, surrounded by blooming yellow wildflowers and peaceful trees. The illustration is rendered in a classic children's storybook style with watercolor textures, pastel tones, and soft hand-drawn lines, evoking a gentle and magical atmosphere.\",\n","    \"Princess_Images_img_5.png\": \"A young princess with flowing golden-brown hair and a golden crown walks joyfully through a vibrant sunflower field. She wears a soft pink gown and smiles warmly as she reaches toward the sunflowers. The background features bright blue skies with fluffy clouds, lush greenery, and colorful wildflowers. The scene is illustrated in a classic children's storybook style with gentle watercolor textures and soft, hand-drawn lines, evoking a peaceful, magical atmosphere.\",\n","\n","    \"Scene_Transitions_img_1.png\": \"A storybook-style digital illustration of a magical forest at sunrise. Golden sunlight filters softly through tall trees, casting a warm glow on a winding dirt path lined with wildflowers. Mist lingers in the distance, and a small stream reflects the morning light. The scene is peaceful and whimsical, rendered in soft watercolor textures and pastel colors, evoking a dreamy, enchanted atmosphere.\",\n","    \"Scene_Transitions_img_2.png\": \"A whimsical, storybook-style digital illustration of a peaceful moonlit meadow. A full moon glows brightly in a starry sky, casting silver light over a gently flowing stream surrounded by soft hills and glowing wildflowers. Large trees frame the scene, and magical blue lotus flowers glow softly near the water's edge. The color palette includes dreamy blues, purples, and soft greens, creating a calm, enchanted nighttime atmosphere with watercolor textures and gentle, painterly details.\",\n","    \"Scene_Transitions_img_3.png\": \"A whimsical, storybook-style digital illustration of an enchanted forest shrouded in soft mist. A winding dirt path disappears into the fog between tall, shadowy trees. Bioluminescent mushrooms and glowing fireflies illuminate the forest floor, surrounded by lush greenery and soft, colorful flowers. The scene is painted in cool blues and greens with warm highlights, using gentle watercolor textures and a dreamy, magical atmosphere.\",\n","    \"Scene_Transitions_img_4.png\": \"A magical storybook-style illustration of a young princess and a young wizard in a moonlit forest clearing, gazing up as a shooting star streaks across the night sky. The wizard holds a glowing wand, and the stream beside them reflects the soft starlight. Tall trees, glowing mushrooms, and gentle wildflowers surround them, with a crescent moon shining above. The scene is rendered in soft watercolor textures and hand-drawn lines, creating a dreamy, enchanting atmosphere.\",\n","    \"Scene_Transitions_img_5.png\": \"A whimsical storybook-style illustration of a glowing forest glade at twilight, where luminous blue crystals float above a mossy stone circle. The scene is surrounded by towering trees, glowing mushrooms, and vibrant wildflowers under a starlit sky. Soft light reflects in a small pond at the center, enhancing the magical atmosphere. The artwork features gentle watercolor textures, warm highlights, and hand-drawn lines, creating an enchanted, dreamlike environmen\",\n","\n","    \"Wizard_Images_img_1.png\": \"A young wizard with curly brown hair and fair skin, wearing a blue robe and a pointed wizard hat, standing in a neutral pose holding a glowing staff. The illustration is in a classic children’s storybook style, with soft comic-like line art, warm textured background, and hand-drawn watercolor shading. Character facing forward, centered, full body, soft lighting.\",\n","    \"Wizard_Images_img_2.png\": \"A young wizard with reddish-brown curly hair, wearing a blue robe and pointed wizard hat, walking forward while casting a glowing golden spiral spell with a wand. Set outdoors on a soft forest path with greenery, in a classic children’s storybook illustration style. Warm tones, watercolor texture, hand-drawn comic style, action pose.\",\n","    \"Wizard_Images_img_3.png\": \"A young wizard with curly reddish-brown hair, wearing a blue robe and pointed wizard hat, walking forward while casting a glowing golden spiral spell with a wand. Set in a lush, sunlit forest with tall trees and soft green foliage. The illustration is in a classic children’s storybook style with hand-drawn comic line art, watercolor texture, warm earthy tones, and magical atmosphere.\",\n","    \"Wizard_Images_img_4.png\": \"A young wizard with curly reddish-brown hair, wearing a blue robe and pointed wizard hat, flying on a wooden broomstick while holding a glowing wand. The background shows soft, fluffy clouds and rolling hills below, in a warm storybook illustration style with watercolor texture, hand-drawn comic lines, and gentle earthy colors.\",\n","    \"Wizard_Images_img_5.png\": \"A young wizard with curly reddish-brown hair, wearing a blue robe and a pointed wizard hat, reading a large spellbook while holding a glowing wand. The background shows a dimly lit stone castle interior with archways and textured walls. The illustration is in a classic children’s storybook style with warm watercolor tones and soft comic-style line art, focused expression on the wizard's face.\"\n","}\n","\n","\n","output_path = \"/content/drive/MyDrive/Colab Notebooks/NLP_DreamBooth/all_training_images/captions.txt\"\n","os.makedirs(os.path.dirname(output_path), exist_ok=True)\n","\n","with open(output_path, \"w\") as f:\n","    for img_name, caption in captions.items():\n","        f.write(f\"{img_name}\\t{caption}\\n\")\n","\n","print(\"✅ Captions saved successfully!\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bs2Ag_V1-Unb","executionInfo":{"status":"ok","timestamp":1745183534946,"user_tz":240,"elapsed":37,"user":{"displayName":"Praveen Vemasani","userId":"00723242222486514580"}},"outputId":"a453113e-279e-48e1-b7cc-fd2d20e1c5d3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Captions saved successfully!\n"]}]},{"cell_type":"code","source":["# 1. Install dependencies\n","!pip install -q diffusers==0.27.2 transformers accelerate bitsandbytes xformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-hBbJ4YjC22B","executionInfo":{"status":"ok","timestamp":1745183737312,"user_tz":240,"elapsed":77855,"user":{"displayName":"Praveen Vemasani","userId":"00723242222486514580"}},"outputId":"f9daaf41-fe18-4acf-e6c9-b1e203741916"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m89.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.4/43.4 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m133.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m99.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m114.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["# 2. Clone the diffusers repo to get the training script\n","!git clone https://github.com/huggingface/diffusers\n","%cd diffusers\n","!pip install -e ."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PByQ0aDZDVQz","executionInfo":{"status":"ok","timestamp":1745183760051,"user_tz":240,"elapsed":15348,"user":{"displayName":"Praveen Vemasani","userId":"00723242222486514580"}},"outputId":"c0d92920-f386-41bd-9651-96f705814c83"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'diffusers'...\n","remote: Enumerating objects: 89855, done.\u001b[K\n","remote: Counting objects: 100% (1572/1572), done.\u001b[K\n","remote: Compressing objects: 100% (1165/1165), done.\u001b[K\n","remote: Total 89855 (delta 839), reused 416 (delta 400), pack-reused 88283 (from 4)\u001b[K\n","Receiving objects: 100% (89855/89855), 67.58 MiB | 16.59 MiB/s, done.\n","Resolving deltas: 100% (65421/65421), done.\n","/content/diffusers\n","Obtaining file:///content/diffusers\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n","  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.11/dist-packages (from diffusers==0.34.0.dev0) (8.6.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from diffusers==0.34.0.dev0) (3.18.0)\n","Requirement already satisfied: huggingface-hub>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from diffusers==0.34.0.dev0) (0.30.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from diffusers==0.34.0.dev0) (2.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from diffusers==0.34.0.dev0) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from diffusers==0.34.0.dev0) (2.32.3)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from diffusers==0.34.0.dev0) (0.5.3)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from diffusers==0.34.0.dev0) (11.1.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.27.0->diffusers==0.34.0.dev0) (2025.3.2)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.27.0->diffusers==0.34.0.dev0) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.27.0->diffusers==0.34.0.dev0) (6.0.2)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.27.0->diffusers==0.34.0.dev0) (4.67.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.27.0->diffusers==0.34.0.dev0) (4.13.2)\n","Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata->diffusers==0.34.0.dev0) (3.21.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.34.0.dev0) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.34.0.dev0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.34.0.dev0) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.34.0.dev0) (2025.1.31)\n","Building wheels for collected packages: diffusers\n","  Building editable for diffusers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for diffusers: filename=diffusers-0.34.0.dev0-0.editable-py3-none-any.whl size=11367 sha256=7cee03516cd77d15c0d0e5ba4e4e272025b13af029ee39f1de0ba76a23537efd\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-meawtmlu/wheels/30/15/ca/ab6e88c89d6ba7047b3f155894c6c346e7cf06067fd132ae62\n","Successfully built diffusers\n","Installing collected packages: diffusers\n","  Attempting uninstall: diffusers\n","    Found existing installation: diffusers 0.27.2\n","    Uninstalling diffusers-0.27.2:\n","      Successfully uninstalled diffusers-0.27.2\n","Successfully installed diffusers-0.34.0.dev0\n"]}]},{"cell_type":"code","source":["# 3. Enable GPU support with xformers\n","!pip install -q xformers==0.0.23"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"edAHUe_rDqFh","executionInfo":{"status":"ok","timestamp":1745183885305,"user_tz":240,"elapsed":122938,"user":{"displayName":"Praveen Vemasani","userId":"00723242222486514580"}},"outputId":"4ebe3c4b-3dd0-4ade-a3bd-6079545fc8d8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.0/213.0 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m128.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m105.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.21.0+cu124 requires torch==2.6.0, but you have torch 2.1.1 which is incompatible.\n","torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.1.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"markdown","source":["STEP 1: Mount Google Drive & Set Paths"],"metadata":{"id":"ionY6ajHE0Db"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","DATA_DIR = \"/content/drive/MyDrive/Colab Notebooks/NLP_DreamBooth/all_training_images\"\n","CAPTIONS_PATH = f\"{DATA_DIR}/captions.txt\"\n","OUTPUT_DIR = \"/content/drive/MyDrive/Colab Notebooks/NLP_DreamBooth/multiverse_model_output\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z2kqH18tDuYm","executionInfo":{"status":"ok","timestamp":1745184033743,"user_tz":240,"elapsed":986,"user":{"displayName":"Praveen Vemasani","userId":"00723242222486514580"}},"outputId":"8e0914e0-913d-4de3-b872-632f24be748d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["STEP 2: Install Required Libraries"],"metadata":{"id":"lXZTihyNE2nZ"}},{"cell_type":"code","source":["%pip install -U diffusers==0.27.2 transformers==4.39.3 huggingface-hub==0.27.0 peft==0.10.0 accelerate bitsandbytes xformers\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MBkiz2GxEwZ-","executionInfo":{"status":"ok","timestamp":1745184180009,"user_tz":240,"elapsed":105925,"user":{"displayName":"Praveen Vemasani","userId":"00723242222486514580"}},"outputId":"ce247cba-430b-4c33-e4da-54312159ad1e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting diffusers==0.27.2\n","  Using cached diffusers-0.27.2-py3-none-any.whl.metadata (18 kB)\n","Collecting transformers==4.39.3\n","  Downloading transformers-4.39.3-py3-none-any.whl.metadata (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting huggingface-hub==0.27.0\n","  Downloading huggingface_hub-0.27.0-py3-none-any.whl.metadata (13 kB)\n","Collecting peft==0.10.0\n","  Downloading peft-0.10.0-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.5.2)\n","Collecting accelerate\n","  Downloading accelerate-1.6.0-py3-none-any.whl.metadata (19 kB)\n","Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.45.5)\n","Requirement already satisfied: xformers in /usr/local/lib/python3.11/dist-packages (0.0.23)\n","Collecting xformers\n","  Using cached xformers-0.0.29.post3-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from diffusers==0.27.2) (8.6.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from diffusers==0.27.2) (3.18.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from diffusers==0.27.2) (2.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from diffusers==0.27.2) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from diffusers==0.27.2) (2.32.3)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from diffusers==0.27.2) (0.5.3)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from diffusers==0.27.2) (11.1.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.39.3) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.39.3) (6.0.2)\n","Collecting tokenizers<0.19,>=0.14 (from transformers==4.39.3)\n","  Downloading tokenizers-0.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.39.3) (4.67.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.27.0) (2025.3.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.27.0) (4.13.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft==0.10.0) (5.9.5)\n","Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from peft==0.10.0) (2.1.1)\n","Collecting torch>=1.13.0 (from peft==0.10.0)\n","  Downloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.10.0) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.10.0) (3.1.6)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.13.0->peft==0.10.0)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.13.0->peft==0.10.0)\n","  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.13.0->peft==0.10.0)\n","  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.13.0->peft==0.10.0)\n","  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.13.0->peft==0.10.0)\n","  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.13.0->peft==0.10.0)\n","  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.13.0->peft==0.10.0)\n","  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.13.0->peft==0.10.0)\n","  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.13.0->peft==0.10.0)\n","  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.10.0) (0.6.2)\n","Collecting nvidia-nccl-cu12==2.21.5 (from torch>=1.13.0->peft==0.10.0)\n","  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n","Collecting nvidia-nvtx-cu12==12.4.127 (from torch>=1.13.0->peft==0.10.0)\n","  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.10.0) (12.4.127)\n","Collecting triton==3.2.0 (from torch>=1.13.0->peft==0.10.0)\n","  Downloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.10.0) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft==0.10.0) (1.3.0)\n","Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->diffusers==0.27.2) (3.21.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.27.2) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.27.2) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.27.2) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.27.2) (2025.1.31)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13.0->peft==0.10.0) (3.0.2)\n","Using cached diffusers-0.27.2-py3-none-any.whl (2.0 MB)\n","Downloading transformers-4.39.3-py3-none-any.whl (8.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m133.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading huggingface_hub-0.27.0-py3-none-any.whl (450 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m450.5/450.5 kB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading peft-0.10.0-py3-none-any.whl (199 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.1/199.1 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading accelerate-1.6.0-py3-none-any.whl (354 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m354.7/354.7 kB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hUsing cached xformers-0.0.29.post3-cp311-cp311-manylinux_2_28_x86_64.whl (43.4 MB)\n","Downloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl (766.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.7/766.7 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hUsing cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.2/253.2 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tokenizers-0.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m118.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, huggingface-hub, torch, tokenizers, diffusers, xformers, transformers, accelerate, peft\n","  Attempting uninstall: triton\n","    Found existing installation: triton 2.1.0\n","    Uninstalling triton-2.1.0:\n","      Successfully uninstalled triton-2.1.0\n","  Attempting uninstall: nvidia-nvtx-cu12\n","    Found existing installation: nvidia-nvtx-cu12 12.1.105\n","    Uninstalling nvidia-nvtx-cu12-12.1.105:\n","      Successfully uninstalled nvidia-nvtx-cu12-12.1.105\n","  Attempting uninstall: nvidia-nccl-cu12\n","    Found existing installation: nvidia-nccl-cu12 2.18.1\n","    Uninstalling nvidia-nccl-cu12-2.18.1:\n","      Successfully uninstalled nvidia-nccl-cu12-2.18.1\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.1.0.106\n","    Uninstalling nvidia-cusparse-cu12-12.1.0.106:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.1.0.106\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.2.106\n","    Uninstalling nvidia-curand-cu12-10.3.2.106:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.2.106\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.0.2.54\n","    Uninstalling nvidia-cufft-cu12-11.0.2.54:\n","      Successfully uninstalled nvidia-cufft-cu12-11.0.2.54\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.1.105\n","    Uninstalling nvidia-cuda-runtime-cu12-12.1.105:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.1.105\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.1.105\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.1.105:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.1.105\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.1.105\n","    Uninstalling nvidia-cuda-cupti-cu12-12.1.105:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.1.105\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.1.3.1\n","    Uninstalling nvidia-cublas-cu12-12.1.3.1:\n","      Successfully uninstalled nvidia-cublas-cu12-12.1.3.1\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.4.5.107\n","    Uninstalling nvidia-cusolver-cu12-11.4.5.107:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.4.5.107\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 8.9.2.26\n","    Uninstalling nvidia-cudnn-cu12-8.9.2.26:\n","      Successfully uninstalled nvidia-cudnn-cu12-8.9.2.26\n","  Attempting uninstall: huggingface-hub\n","    Found existing installation: huggingface-hub 0.30.2\n","    Uninstalling huggingface-hub-0.30.2:\n","      Successfully uninstalled huggingface-hub-0.30.2\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.1.1\n","    Uninstalling torch-2.1.1:\n","      Successfully uninstalled torch-2.1.1\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.21.1\n","    Uninstalling tokenizers-0.21.1:\n","      Successfully uninstalled tokenizers-0.21.1\n","  Attempting uninstall: diffusers\n","    Found existing installation: diffusers 0.34.0.dev0\n","    Uninstalling diffusers-0.34.0.dev0:\n","      Successfully uninstalled diffusers-0.34.0.dev0\n","  Attempting uninstall: xformers\n","    Found existing installation: xformers 0.0.23\n","    Uninstalling xformers-0.0.23:\n","      Successfully uninstalled xformers-0.0.23\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.51.3\n","    Uninstalling transformers-4.51.3:\n","      Successfully uninstalled transformers-4.51.3\n","  Attempting uninstall: accelerate\n","    Found existing installation: accelerate 1.5.2\n","    Uninstalling accelerate-1.5.2:\n","      Successfully uninstalled accelerate-1.5.2\n","  Attempting uninstall: peft\n","    Found existing installation: peft 0.14.0\n","    Uninstalling peft-0.14.0:\n","      Successfully uninstalled peft-0.14.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","sentence-transformers 3.4.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.39.3 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed accelerate-1.6.0 diffusers-0.27.2 huggingface-hub-0.27.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvtx-cu12-12.4.127 peft-0.10.0 tokenizers-0.15.2 torch-2.6.0 transformers-4.39.3 triton-3.2.0 xformers-0.0.29.post3\n"]}]},{"cell_type":"markdown","source":[" STEP 3: Clone Diffusers & Install Locally"],"metadata":{"id":"Y5I8FJP-FAc6"}},{"cell_type":"code","source":["!git clone https://github.com/huggingface/diffusers.git\n","%cd diffusers\n","!pip install -e ."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xE0OF7mmFGHI","executionInfo":{"status":"ok","timestamp":1745184202933,"user_tz":240,"elapsed":15592,"user":{"displayName":"Praveen Vemasani","userId":"00723242222486514580"}},"outputId":"13df067c-7f0a-4b54-cf54-c29332423a4a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'diffusers'...\n","remote: Enumerating objects: 89855, done.\u001b[K\n","remote: Counting objects: 100% (1572/1572), done.\u001b[K\n","remote: Compressing objects: 100% (1166/1166), done.\u001b[K\n","remote: Total 89855 (delta 838), reused 415 (delta 399), pack-reused 88283 (from 4)\u001b[K\n","Receiving objects: 100% (89855/89855), 67.78 MiB | 15.72 MiB/s, done.\n","Resolving deltas: 100% (65435/65435), done.\n","/content/diffusers/diffusers\n","Obtaining file:///content/diffusers/diffusers\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n","  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.11/dist-packages (from diffusers==0.34.0.dev0) (8.6.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from diffusers==0.34.0.dev0) (3.18.0)\n","Requirement already satisfied: huggingface-hub>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from diffusers==0.34.0.dev0) (0.27.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from diffusers==0.34.0.dev0) (2.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from diffusers==0.34.0.dev0) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from diffusers==0.34.0.dev0) (2.32.3)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from diffusers==0.34.0.dev0) (0.5.3)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from diffusers==0.34.0.dev0) (11.1.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.27.0->diffusers==0.34.0.dev0) (2025.3.2)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.27.0->diffusers==0.34.0.dev0) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.27.0->diffusers==0.34.0.dev0) (6.0.2)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.27.0->diffusers==0.34.0.dev0) (4.67.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.27.0->diffusers==0.34.0.dev0) (4.13.2)\n","Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata->diffusers==0.34.0.dev0) (3.21.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.34.0.dev0) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.34.0.dev0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.34.0.dev0) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.34.0.dev0) (2025.1.31)\n","Building wheels for collected packages: diffusers\n","  Building editable for diffusers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for diffusers: filename=diffusers-0.34.0.dev0-0.editable-py3-none-any.whl size=11368 sha256=faf8963877d70a6290da8f2ff1c5445a563836d0bf8b5cec6608762255585e63\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-qlsoaplf/wheels/7a/15/59/7fa5263821a670d6646f03cc5097ad4520f9ae25a87ea19e13\n","Successfully built diffusers\n","Installing collected packages: diffusers\n","  Attempting uninstall: diffusers\n","    Found existing installation: diffusers 0.27.2\n","    Uninstalling diffusers-0.27.2:\n","      Successfully uninstalled diffusers-0.27.2\n","Successfully installed diffusers-0.34.0.dev0\n"]}]},{"cell_type":"markdown","source":[" Launch Training"],"metadata":{"id":"cOLasneGFnXk"}},{"cell_type":"code","source":["import os\n","import shutil\n","\n","folder = \"/content/drive/MyDrive/Colab Notebooks/NLP_DreamBooth/all_training_images\"\n","captions_txt = os.path.join(folder, \"captions.txt\")\n","\n","# Move it one level up\n","new_path = os.path.join(os.path.dirname(folder), \"captions.txt\")\n","shutil.move(captions_txt, new_path)\n","\n","print(f\"✅ Moved captions.txt to: {new_path}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yr_aDGgSFr_t","executionInfo":{"status":"ok","timestamp":1745184616925,"user_tz":240,"elapsed":16,"user":{"displayName":"Praveen Vemasani","userId":"00723242222486514580"}},"outputId":"a6a60c93-b589-40b8-ab7a-8aa36c296901"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Moved captions.txt to: /content/drive/MyDrive/Colab Notebooks/NLP_DreamBooth/captions.txt\n"]}]},{"cell_type":"code","source":["import os\n","\n","image_folder = \"/content/drive/MyDrive/Colab Notebooks/NLP_DreamBooth/all_training_images\"\n","\n","# Delete all .txt files inside image folder\n","for fname in os.listdir(image_folder):\n","    if fname.endswith(\".txt\"):\n","        os.remove(os.path.join(image_folder, fname))\n","\n","print(\"✅ Cleaned all .txt files from training folder.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N2jxO5nFGQPx","executionInfo":{"status":"ok","timestamp":1745184740953,"user_tz":240,"elapsed":22,"user":{"displayName":"Praveen Vemasani","userId":"00723242222486514580"}},"outputId":"af82b2f6-fba5-4a61-ffc5-ec6ecc6ac1af"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Cleaned all .txt files from training folder.\n"]}]},{"cell_type":"code","source":["%cd diffusers\n","\n","!accelerate launch examples/dreambooth/train_dreambooth_lora_sdxl.py \\\n","  --pretrained_model_name_or_path=\"stabilityai/stable-diffusion-xl-base-1.0\" \\\n","  --instance_data_dir=\"/content/drive/MyDrive/Colab Notebooks/NLP_DreamBooth/all_training_images\" \\\n","  --output_dir=\"/content/drive/MyDrive/Colab Notebooks/NLP_DreamBooth/multiverse_model_output\" \\\n","  --instance_prompt=\"storybook illustration\" \\\n","  --resolution=1024 \\\n","  --train_batch_size=1 \\\n","  --gradient_accumulation_steps=4 \\\n","  --learning_rate=1e-4 \\\n","  --lr_scheduler=\"constant\" \\\n","  --max_train_steps=300 \\\n","  --checkpointing_steps=100 \\\n","  --seed=42 \\\n","  --mixed_precision=\"fp16\" \\\n","  --use_8bit_adam \\\n","  --enable_xformers_memory_efficient_attention \\\n","  --train_text_encoder\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1MiHySK-FWHr","executionInfo":{"status":"ok","timestamp":1745186587855,"user_tz":240,"elapsed":1837493,"user":{"displayName":"Praveen Vemasani","userId":"00723242222486514580"}},"outputId":"0e938cb4-3086-44e3-cd5c-ecdcc3c294c2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[Errno 2] No such file or directory: 'diffusers'\n","/content/diffusers/diffusers\n","The following values were not passed to `accelerate launch` and had defaults used instead:\n","\t`--num_processes` was set to a value of `1`\n","\t`--num_machines` was set to a value of `1`\n","\t`--mixed_precision` was set to a value of `'no'`\n","\t`--dynamo_backend` was set to a value of `'no'`\n","To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n","2025-04-20 21:32:40.931680: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1745184760.954137   14631 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1745184760.960559   14631 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","04/20/2025 21:32:45 - INFO - __main__ - Distributed environment: DistributedType.NO\n","Num processes: 1\n","Process index: 0\n","Local process index: 0\n","Device: cuda\n","\n","Mixed precision type: fp16\n","\n","/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n","You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n","{'rescale_betas_zero_snr', 'clip_sample_range', 'dynamic_thresholding_ratio', 'variance_type', 'thresholding'} was not found in config. Values will be initialized to default values.\n","{'shift_factor', 'latents_mean', 'mid_block_add_attention', 'use_quant_conv', 'latents_std', 'use_post_quant_conv'} was not found in config. Values will be initialized to default values.\n","All model checkpoint weights were used when initializing AutoencoderKL.\n","\n","All the weights of AutoencoderKL were initialized from the model checkpoint at stabilityai/stable-diffusion-xl-base-1.0.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.\n","{'attention_type', 'reverse_transformer_layers_per_block', 'dropout'} was not found in config. Values will be initialized to default values.\n","All model checkpoint weights were used when initializing UNet2DConditionModel.\n","\n","All the weights of UNet2DConditionModel were initialized from the model checkpoint at stabilityai/stable-diffusion-xl-base-1.0.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use UNet2DConditionModel for predictions without further training.\n","04/20/2025 21:32:59 - INFO - __main__ - ***** Running training *****\n","04/20/2025 21:32:59 - INFO - __main__ -   Num examples = 20\n","04/20/2025 21:32:59 - INFO - __main__ -   Num batches each epoch = 20\n","04/20/2025 21:32:59 - INFO - __main__ -   Num Epochs = 60\n","04/20/2025 21:32:59 - INFO - __main__ -   Instantaneous batch size per device = 1\n","04/20/2025 21:32:59 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 4\n","04/20/2025 21:32:59 - INFO - __main__ -   Gradient Accumulation steps = 4\n","04/20/2025 21:32:59 - INFO - __main__ -   Total optimization steps = 300\n","Steps:  33% 100/300 [09:55<19:50,  5.95s/it, loss=0.245, lr=0.0001]04/20/2025 21:42:55 - INFO - accelerate.accelerator - Saving current state to /content/drive/MyDrive/Colab Notebooks/NLP_DreamBooth/multiverse_model_output/checkpoint-100\n","Model weights saved in /content/drive/MyDrive/Colab Notebooks/NLP_DreamBooth/multiverse_model_output/checkpoint-100/pytorch_lora_weights.safetensors\n","04/20/2025 21:42:57 - INFO - accelerate.checkpointing - Optimizer state saved in /content/drive/MyDrive/Colab Notebooks/NLP_DreamBooth/multiverse_model_output/checkpoint-100/optimizer.bin\n","04/20/2025 21:42:57 - INFO - accelerate.checkpointing - Scheduler state saved in /content/drive/MyDrive/Colab Notebooks/NLP_DreamBooth/multiverse_model_output/checkpoint-100/scheduler.bin\n","04/20/2025 21:42:57 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in /content/drive/MyDrive/Colab Notebooks/NLP_DreamBooth/multiverse_model_output/checkpoint-100/sampler.bin\n","04/20/2025 21:42:57 - INFO - accelerate.checkpointing - Gradient scaler state saved in /content/drive/MyDrive/Colab Notebooks/NLP_DreamBooth/multiverse_model_output/checkpoint-100/scaler.pt\n","04/20/2025 21:42:57 - INFO - accelerate.checkpointing - Random states saved in /content/drive/MyDrive/Colab Notebooks/NLP_DreamBooth/multiverse_model_output/checkpoint-100/random_states_0.pkl\n","04/20/2025 21:42:57 - INFO - __main__ - Saved state to /content/drive/MyDrive/Colab Notebooks/NLP_DreamBooth/multiverse_model_output/checkpoint-100\n","Steps:  67% 200/300 [19:54<10:01,  6.01s/it, loss=0.0223, lr=0.0001]04/20/2025 21:52:54 - INFO - accelerate.accelerator - Saving current state to /content/drive/MyDrive/Colab Notebooks/NLP_DreamBooth/multiverse_model_output/checkpoint-200\n","Model weights saved in /content/drive/MyDrive/Colab Notebooks/NLP_DreamBooth/multiverse_model_output/checkpoint-200/pytorch_lora_weights.safetensors\n","04/20/2025 21:52:55 - INFO - accelerate.checkpointing - Optimizer state saved in /content/drive/MyDrive/Colab Notebooks/NLP_DreamBooth/multiverse_model_output/checkpoint-200/optimizer.bin\n","04/20/2025 21:52:55 - INFO - accelerate.checkpointing - Scheduler state saved in /content/drive/MyDrive/Colab Notebooks/NLP_DreamBooth/multiverse_model_output/checkpoint-200/scheduler.bin\n","04/20/2025 21:52:55 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in /content/drive/MyDrive/Colab Notebooks/NLP_DreamBooth/multiverse_model_output/checkpoint-200/sampler.bin\n","04/20/2025 21:52:55 - INFO - accelerate.checkpointing - Gradient scaler state saved in /content/drive/MyDrive/Colab Notebooks/NLP_DreamBooth/multiverse_model_output/checkpoint-200/scaler.pt\n","04/20/2025 21:52:55 - INFO - accelerate.checkpointing - Random states saved in /content/drive/MyDrive/Colab Notebooks/NLP_DreamBooth/multiverse_model_output/checkpoint-200/random_states_0.pkl\n","04/20/2025 21:52:55 - INFO - __main__ - Saved state to /content/drive/MyDrive/Colab Notebooks/NLP_DreamBooth/multiverse_model_output/checkpoint-200\n","Steps: 100% 300/300 [29:52<00:00,  5.97s/it, loss=0.2, lr=0.0001]04/20/2025 22:02:52 - INFO - accelerate.accelerator - Saving current state to /content/drive/MyDrive/Colab Notebooks/NLP_DreamBooth/multiverse_model_output/checkpoint-300\n","Model weights saved in /content/drive/MyDrive/Colab Notebooks/NLP_DreamBooth/multiverse_model_output/checkpoint-300/pytorch_lora_weights.safetensors\n","04/20/2025 22:02:54 - INFO - accelerate.checkpointing - Optimizer state saved in /content/drive/MyDrive/Colab Notebooks/NLP_DreamBooth/multiverse_model_output/checkpoint-300/optimizer.bin\n","04/20/2025 22:02:54 - INFO - accelerate.checkpointing - Scheduler state saved in /content/drive/MyDrive/Colab Notebooks/NLP_DreamBooth/multiverse_model_output/checkpoint-300/scheduler.bin\n","04/20/2025 22:02:54 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in /content/drive/MyDrive/Colab Notebooks/NLP_DreamBooth/multiverse_model_output/checkpoint-300/sampler.bin\n","04/20/2025 22:02:54 - INFO - accelerate.checkpointing - Gradient scaler state saved in /content/drive/MyDrive/Colab Notebooks/NLP_DreamBooth/multiverse_model_output/checkpoint-300/scaler.pt\n","04/20/2025 22:02:54 - INFO - accelerate.checkpointing - Random states saved in /content/drive/MyDrive/Colab Notebooks/NLP_DreamBooth/multiverse_model_output/checkpoint-300/random_states_0.pkl\n","04/20/2025 22:02:54 - INFO - __main__ - Saved state to /content/drive/MyDrive/Colab Notebooks/NLP_DreamBooth/multiverse_model_output/checkpoint-300\n","Steps: 100% 300/300 [29:54<00:00,  5.97s/it, loss=0.0199, lr=0.0001]Model weights saved in /content/drive/MyDrive/Colab Notebooks/NLP_DreamBooth/multiverse_model_output/pytorch_lora_weights.safetensors\n","Instantiating AutoencoderKL model under default dtype torch.float16.\n","{'shift_factor', 'latents_mean', 'mid_block_add_attention', 'use_quant_conv', 'latents_std', 'use_post_quant_conv'} was not found in config. Values will be initialized to default values.\n","All model checkpoint weights were used when initializing AutoencoderKL.\n","\n","All the weights of AutoencoderKL were initialized from the model checkpoint at stabilityai/stable-diffusion-xl-base-1.0.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.\n","\n","Fetching 17 files:   0% 0/17 [00:00<?, ?it/s]\u001b[A\n","\n","diffusion_pytorch_model.safetensors:   0% 0.00/335M [00:00<?, ?B/s]\u001b[A\u001b[A\n","\n","diffusion_pytorch_model.safetensors:   9% 31.5M/335M [00:00<00:00, 303MB/s]\u001b[A\u001b[A\n","\n","diffusion_pytorch_model.safetensors:  25% 83.9M/335M [00:00<00:00, 426MB/s]\u001b[A\u001b[A\n","\n","diffusion_pytorch_model.safetensors:  41% 136M/335M [00:00<00:00, 465MB/s] \u001b[A\u001b[A\n","\n","diffusion_pytorch_model.safetensors:  56% 189M/335M [00:00<00:00, 482MB/s]\u001b[A\u001b[A\n","\n","diffusion_pytorch_model.safetensors:  72% 241M/335M [00:00<00:00, 490MB/s]\u001b[A\u001b[A\n","\n","diffusion_pytorch_model.safetensors: 100% 335M/335M [00:00<00:00, 473MB/s]\n","\n","Fetching 17 files: 100% 17/17 [00:00<00:00, 17.37it/s]\n","{'feature_extractor', 'image_encoder'} was not found in config. Values will be initialized to default values.\n","\n","Loading pipeline components...:   0% 0/7 [00:00<?, ?it/s]\u001b[ALoaded tokenizer_2 as CLIPTokenizer from `tokenizer_2` subfolder of stabilityai/stable-diffusion-xl-base-1.0.\n","Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of stabilityai/stable-diffusion-xl-base-1.0.\n","\n","Loading pipeline components...:  29% 2/7 [00:00<00:01,  2.95it/s]\u001b[ALoaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of stabilityai/stable-diffusion-xl-base-1.0.\n","{'timestep_type', 'use_exponential_sigmas', 'final_sigmas_type', 'rescale_betas_zero_snr', 'use_beta_sigmas', 'sigma_min', 'sigma_max'} was not found in config. Values will be initialized to default values.\n","Loaded scheduler as EulerDiscreteScheduler from `scheduler` subfolder of stabilityai/stable-diffusion-xl-base-1.0.\n","Instantiating UNet2DConditionModel model under default dtype torch.float16.\n","{'attention_type', 'reverse_transformer_layers_per_block', 'dropout'} was not found in config. Values will be initialized to default values.\n","All model checkpoint weights were used when initializing UNet2DConditionModel.\n","\n","All the weights of UNet2DConditionModel were initialized from the model checkpoint at /root/.cache/huggingface/hub/models--stabilityai--stable-diffusion-xl-base-1.0/snapshots/462165984030d82259a11f4367a4eed129e94a7b/unet.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use UNet2DConditionModel for predictions without further training.\n","Loaded unet as UNet2DConditionModel from `unet` subfolder of stabilityai/stable-diffusion-xl-base-1.0.\n","\n","Loading pipeline components...:  86% 6/7 [00:05<00:00,  1.08it/s]\u001b[ALoaded text_encoder_2 as CLIPTextModelWithProjection from `text_encoder_2` subfolder of stabilityai/stable-diffusion-xl-base-1.0.\n","\n","Loading pipeline components...: 100% 7/7 [00:06<00:00,  1.02it/s]\n","Loading unet.\n","Loading text_encoder.\n","Loading text_encoder_2.\n","Steps: 100% 300/300 [30:05<00:00,  6.02s/it, loss=0.0199, lr=0.0001]\n"]}]},{"cell_type":"markdown","source":["Zip Trained Model for Download"],"metadata":{"id":"_uVBm3FqNX0S"}},{"cell_type":"code","source":["import shutil\n","import os\n","\n","model_dir = \"/content/drive/MyDrive/Colab Notebooks/NLP_DreamBooth/multiverse_model_output\"\n","zip_path = \"/content/drive/MyDrive/Colab Notebooks/NLP_DreamBooth/multiverse_model_output.zip\"\n","\n","# Remove old zip if it exists\n","if os.path.exists(zip_path):\n","    os.remove(zip_path)\n","\n","# Create new zip\n","shutil.make_archive(zip_path.replace(\".zip\", \"\"), 'zip', model_dir)\n","\n","print(\"✅ Model zipped successfully!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KogQR8qMHfna","executionInfo":{"status":"ok","timestamp":1745186622290,"user_tz":240,"elapsed":9197,"user":{"displayName":"Praveen Vemasani","userId":"00723242222486514580"}},"outputId":"61e14941-e008-43cc-b7af-1dd510e922ed"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Model zipped successfully!\n"]}]},{"cell_type":"markdown","source":["Download .zip to local machine"],"metadata":{"id":"TxOk7hSzN_XQ"}},{"cell_type":"code","source":["from google.colab import files\n","\n","# Make sure only one `.zip` extension is added\n","files.download(\"/content/drive/MyDrive/Colab Notebooks/NLP_DreamBooth/multiverse_model_output.zip\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"X2GUl1RaODAd","executionInfo":{"status":"ok","timestamp":1745186689436,"user_tz":240,"elapsed":55,"user":{"displayName":"Praveen Vemasani","userId":"00723242222486514580"}},"outputId":"ee82d4db-7bdf-4d8a-ed55-dc0ef9871c2b"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_20501dd7-809b-452f-a922-ee9f896444ae\", \"multiverse_model_output.zip\", 165412301)"]},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"iFHXXQnUOnw8"},"execution_count":null,"outputs":[]}]}